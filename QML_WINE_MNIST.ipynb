{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYGVHUZsLNEv1ecKdWxw4v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MirandaCarou/Quantum-Machine-Learning/blob/main/QML_WINE_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **[ PRÁCTICA QML ]** -   **Miranda Carou Laiño**"
      ],
      "metadata": {
        "id": "kHRkQcIga3mA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSQ5xdTramiZ",
        "outputId": "1012d9fd-a515-4ef3-ca50-5ff78ae13544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting qiskit\n",
            "  Downloading qiskit-1.3.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting rustworkx>=0.15.0 (from qiskit)\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n",
            "Collecting dill>=0.3 (from qiskit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Downloading qiskit-1.3.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, rustworkx, pbr, dill, stevedore, qiskit\n",
            "Successfully installed dill-0.3.9 pbr-6.1.0 qiskit-1.3.1 rustworkx-0.15.1 stevedore-5.4.0 symengine-0.13.0\n",
            "Collecting pylatexenc\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136816 sha256=c455e171db5e61567e1df71bb849619816673d8f45a1e2a070d61c377d41e303\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc\n",
            "Successfully installed pylatexenc-2.10\n",
            "Collecting qiskit_algorithms\n",
            "  Downloading qiskit_algorithms-0.3.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: qiskit>=0.44 in /usr/local/lib/python3.10/dist-packages (from qiskit_algorithms) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_algorithms) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_algorithms) (1.26.4)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.44->qiskit_algorithms) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.44->qiskit_algorithms) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=0.44->qiskit_algorithms) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=0.44->qiskit_algorithms) (1.3.0)\n",
            "Downloading qiskit_algorithms-0.3.1-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit_algorithms\n",
            "Successfully installed qiskit_algorithms-0.3.1\n",
            "Collecting qiskit_machine_learning\n",
            "  Downloading qiskit_machine_learning-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: qiskit>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=40.1 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (75.1.0)\n",
            "Requirement already satisfied: dill>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_machine_learning) (0.3.9)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.15.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (4.12.2)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=1.0->qiskit_machine_learning) (0.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2->qiskit_machine_learning) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=1.0->qiskit_machine_learning) (1.17.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=1.0->qiskit_machine_learning) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=1.0->qiskit_machine_learning) (1.3.0)\n",
            "Downloading qiskit_machine_learning-0.8.1-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.1/231.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: qiskit_machine_learning\n",
            "Successfully installed qiskit_machine_learning-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install qiskit\n",
        "!pip install pylatexenc\n",
        "!pip install qiskit_algorithms\n",
        "!pip install qiskit_machine_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The dataset is composed of 178 instances, each of them composed of 13 features\n",
        "(alcohol, malic acid, ash, etc.) and a target label representing one of each of\n",
        "the three possible classes of wine.*"
      ],
      "metadata": {
        "id": "G8sDOsPdj_bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from qiskit import *\n",
        "from qiskit.circuit.library import ZZFeatureMap, PauliFeatureMap, ZFeatureMap, StatePreparation, Initialize\n",
        "from qiskit.circuit.library import RealAmplitudes, TwoLocal, EfficientSU2\n",
        "from qiskit_algorithms.optimizers import COBYLA, ADAM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn . datasets import load_wine\n",
        "from qiskit_machine_learning.algorithms import VQC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from qiskit_machine_learning.utils import algorithm_globals\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "wine_data = load_wine ()\n",
        "features = wine_data . data\n",
        "labels = wine_data . target"
      ],
      "metadata": {
        "id": "ZJXF7tTRjn0y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocesamiento**\n"
      ],
      "metadata": {
        "id": "g_sdUZzlbC8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La etapa de preprocesamiento de los datos es una de las etapas más importantes y pueden marcar la diferencia entre un buen modelo y un mal modelos. Dentro de area de Machine Learning, la etapa de preprocesamiento de datos se puede dividir en 3 partes princiapales:\n",
        "\n",
        "\n",
        "1.   **Integración de los datos**. Unificación de datos datos combinados de diferentes fuentes para ofrecer al usuario un punto de vista de los datos\n",
        "2.   **Limpieza de los datos**. Proceso de detección y correción o eliminación de datos incorrectos o redundantos.\n",
        "3.   **Transformaicón de los datos**: Procesor de convertir los datos a un formato más adecuado para el tratamiento y análisis.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-CiLmo_Kb4sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "features_normalized = scaler.fit_transform(features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_normalized, labels, test_size=0.2, random_state=42) #80% entrenamiento 20% prueba\n",
        "\n",
        "print(\"Training features shape:\", X_train.shape)\n",
        "print(\"Test features shape:\", X_test.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Test labels shape:\", y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mugh2qHXjLDY",
        "outputId": "83679295-7d5f-42a3-f203-3b37eb9bc30f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training features shape: (142, 13)\n",
            "Test features shape: (36, 13)\n",
            "Training labels shape: (142,)\n",
            "Test labels shape: (36,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Encoding**"
      ],
      "metadata": {
        "id": "Gbd7s-tnjB3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La codificación de los datos tambien es algo crucial en QML y suele recibir los nombres de \"Data enncoding\", \"Data Embeding\" o \"Loading\". Es un proceso que consiste principalmente en mapear los datos clásicos a datos cuanticos, unos pasos posteriores que ya dependen más del algoritmo que vayas a implementar y finalmente realizar las medidas y mapear los datos quanticos a clasicos.\n",
        "\n",
        "Existen diferentes métodos de data embeding:\n",
        "\n",
        "1. **Basis encoding**: Es el método más simple. Asocias un cadena de N-bit clásicos con unas bases computaiconales. Util cuando trabajas con numeros en binario.\n",
        "2. **Amplitude Encoding** Método en el que codificas los datos clásicos en las amplitudes de los estaods pero necesita que anteriormente tengas ese vector normalizado\n",
        "3. **Angle encoding**: Método donde condificas los datos clásicos como rotaciones de los angulos de los qubits pero en este caso solo codifcas uno en uno , no todo el dataset entero de golpe. Este método es bueno pra evitar problemas de decoherencia.\n",
        "4. **Feature maps**: (Lo especificados para esta práctica). Donde tenemos 3 opciones posibles:\n",
        "\n",
        "  *   **Codificación Arbitraría** Codifica de manera arbitraria N caracterissticas como rotaciones de N puertas parametrizadas en n qubits y solo codificas de cada vez un punto. Usa una constante n que indica la profundidad del circuito\n",
        "  *   **Feature maps** Mapea un vector de caracteristicas clásico en un vector cuántico del espcio de Hlbert.\n",
        "\n",
        "  Ejemplos:\n",
        "\n",
        "  1.   Circuitos de codificación: **PauliFeatureMap, ZFeatureMap, ZZFeatureMap**\n",
        "  2.   Circuitos de preparacion de datos : **StatePreparation, Initialize**\n",
        "\n",
        "  En el contexto de esta práctica, solo usaré como prueba, los circuitos de codificación porque al final, a diferencia de los otros, estos tienen como proposito codificar los datos en estados cuánticos para usar en algoritmos de machine learning y ya se pasan como parámetros de circuitos parametrizados.\n",
        "\n",
        "    *   **PauliFeatureMap** Usa combinaciones de operadores de Pauli. Es más recomendable para capturar interaciones complejas en los datos (*Deprecated since version 1.3_pending*)\n",
        "    *   **ZFeatureMap**: Codifica los datos usando únicamente operadores de Pauli Z. E muy simple y rápido, muy bueno para datos con poca complejidad\n",
        "    *   **ZZFeatureMap**: Codifica los datos usando interacciones de segundo orden entre qubits. Muy bueno cuando las correlaciones entre las caracteristicas del dataset con algo importante.\n",
        "\n",
        "  En el contexto de nuestro dataset parece que la mejor opción es ZZFeatureMap ya que vamos a clasificar vinos en función de sus propiedades químicas\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iswLwDeLjINI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ZZFeautreMap**"
      ],
      "metadata": {
        "id": "It_TcdXerVq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zz_feature_map = ZZFeatureMap(feature_dimension=X_train.shape[1], reps=2)"
      ],
      "metadata": {
        "id": "ZJyZnBkxlOyG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ZFeatureeMap**"
      ],
      "metadata": {
        "id": "vUO0Z59DtAtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map = ZFeatureMap(X_train.shape[1], reps=2, insert_barriers=True)"
      ],
      "metadata": {
        "id": "iW8dJvIPs0H0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encontrar el Ansatz apropiado**\n"
      ],
      "metadata": {
        "id": "8QLU58UgucX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para seguir contruyendo nuestro modelos necesitamos encontrar el estado de referencia por el que vamos a empezar a enfrentar el problema. Podemos elegirlo manualmente o usar un circuito plantilla como lo son por ejemplo: **TwoLocal** , **RealAmplitude** o **EfficientSU2**\n",
        "\n",
        "- *Escogo siempre el tipo de entralazamiento lineal asi de primeras porque sobrecarga menos el circuito, es más rápido y menos propensos a errores*"
      ],
      "metadata": {
        "id": "-PNZF0nqutbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RealAmplitudes**\n",
        "\n",
        "En mi sincera opinión, creo que este es el más popular para problemas de clasificación y quantum machine learning. Es simple y eficaz. Se basa en puertas rotacionales RY y entrelazamientos entre qubits.\n",
        "\n",
        "*Creo que para nuestro dataset es el que mejor podría manejar las correlaciones y no ser muy demandante para mi ordenador.*"
      ],
      "metadata": {
        "id": "eGgi-1bgwZif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ansatz_amplitudes = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='linear',\n",
        "                        reps=2,\n",
        "                        insert_barriers=True)"
      ],
      "metadata": {
        "id": "CG_2OUCxueBg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TwoLocal**\n",
        "\n",
        "Ese ya es un circuito más genéricos y personalizable que combina las puertas rotacionales y las de entrelazamiento. Es una opción mucho más versátil que puede ser muy interesante pero tambien es una opción mucho mas dificil de optimizar y va a consumirte muchos mas recursos del ordenador, que si no tienes un ordenador muy potente esto puede jugar en tu contra."
      ],
      "metadata": {
        "id": "heYvhT4ly15N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ansatz_twolocal = TwoLocal(num_qubits=X_train.shape[1],\n",
        "                           rotation_blocks='ry',\n",
        "                           entanglement_blocks='cz',\n",
        "                           reps=2,\n",
        "                           insert_barriers=True)"
      ],
      "metadata": {
        "id": "DcUy6dve0do-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EfficientSU2**\n",
        "\n",
        "Esta es la optión más ligera para utilizar pero también la más limitada pero si tienes muchas limitaciones de hardware es la mejor opción aunque va a tener más dificultades para encontrarte correlaciones complejas en el dataset. Se basa en puertas RY y Rz para las rotaciones y puertas CNOT para los acoplamientos.\n"
      ],
      "metadata": {
        "id": "ZnOewRlG02c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ansatz_su2 = EfficientSU2(num_qubits=X_train.shape[1],\n",
        "                          reps=2,\n",
        "                          insert_barriers=True)"
      ],
      "metadata": {
        "id": "1Lfdtzsd11Z9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Optimizador**\n",
        "\n",
        "Encontrar un buen optimizador tambien es parte esencial de todo algoritmo variacional y que es lo que se utiliza para evaluar y seleccionar los parametros del siguiente recorrido del bucle variacional, al menos hasta encontrar un estado estable.\n",
        "\n",
        "A grandes escalas hay dos tipos de optimizadores:\n",
        "\n",
        "1.   **Locales**: Buscan el punto donde se minimice la función de coste, empezando desde el punto incial y luego se va moviendo en base a lo que va observando dentro de la región donde esta y no pueden ver más alla de su region. Son optimizadores que por lo general convergen rápido pero que tambien dependen del punto inicial donde empiecen. Muy sensible a minimos locales\n",
        "\n",
        "2.   **Globales** : Buscan el punto donde se minimiza la función de coste pero en distintas regiones. Es menos sensible que el anterior a minimos locales pero converge mucho mas lento.Obviamente tambien es una opción que requiere muchos más recursos computacionales (*En principio no me remplanteo esta opción por ser las más lenta y pesada*)\n",
        "\n",
        "3.  **Gradient-Based**: Busca el mínimo de la función de coste navegando por el campo de perdidas. Calcula el gradiente de la función de pérdidas con respecto a los parámentros. Es muy eficiente para espacios suaves pero clacular gradientes suele ser costoso en cuántica  y además es muy sensible a inicializar mal los parámetros.  \n",
        "\n",
        "4. **Libre de Gradiente**: No necesita calcular grandiente, en vez de eso, evalua la función de pérdida en diferentes puntos. Esta es una opción bastante funcional y buena si tienes problemas de ruido. Si que es verdad que no es muy eficiente para problemas de muchas variables. (*No voy a considerar esta opción como prueba porque al no estar utilizando hardware real muy sensible al rudio y puedo calcular gradientes, no me tiene sentido*)\n",
        "\n",
        "\n",
        "Mis 3 posibles opciones para pruebas son:\n",
        "\n",
        "*   **COBYLA** (optimizador local): Opción simple y eficiente si el circuito no es muy complejo\n",
        "*   **Adam** (basado en gradiente): Ya conocido y utilizado de la practica anterior\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Iphc8oqS3E-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COBYLA**"
      ],
      "metadata": {
        "id": "mRbKgmZu9zcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_cobyla = COBYLA(maxiter=500, tol=1e-3)"
      ],
      "metadata": {
        "id": "r4ty16B094QX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADAM**"
      ],
      "metadata": {
        "id": "FDjPChZ3-J_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_adam = ADAM(maxiter=500, lr=0.01)"
      ],
      "metadata": {
        "id": "Q_1Q0FCp-IhH"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Quantum Neural Network Models**"
      ],
      "metadata": {
        "id": "9McnHhWXbJ64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelos más secillos y rápidos**\n",
        "\n",
        "*Mi intención es intentar validar primero el flujo general del modelo y luego ya después probar configuraciones más avanzadas*\n",
        "\n",
        "  - **MODELO-1**\n",
        "\n",
        "    *   ZFeatureMap\n",
        "    *   RealAmplitudes\n",
        "    *   COBYLA"
      ],
      "metadata": {
        "id": "B7xuMBO9GDJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_1 = ZFeatureMap(X_train.shape[1], reps=2, insert_barriers=True)\n",
        "ansatz_amplitudes_1 = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='linear',\n",
        "                        reps=2)\n",
        "optimizer_cobyla_1 = COBYLA(maxiter=50, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc = VQC(feature_map=z_feature_map_1, ansatz=ansatz_amplitudes_1, optimizer=optimizer_cobyla_1)\n",
        "\n",
        "start = time.time()\n",
        "vqc.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time} segundos\")\n",
        "\n",
        "train_score = vqc.score(X_train, y_train)\n",
        "test_score = vqc.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGqGgiJaGZL1",
        "outputId": "abd71784-550f-4602-b37b-8eb3c45750bd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 1454.4215223789215 segundos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.5\n",
            "Precisión del VQC en el conjunto de prueba: 0.5833333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "elapsed_time_minutes = elapsed_time / 60  # Convertir segundos a minutos\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.2f} minutos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTCxrZfXuOdD",
        "outputId": "33aa8ec6-54d9-4606-8c0a-9ab2f0353152"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 24.24 minutos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **MODELO-2**\n",
        "\n",
        "  *   **ZFeatureMap**: 2 repeticiones\n",
        "  *   **EfficientSU2**: 1 repetición\n",
        "  *   **COBYLA**: 300 interacciones (*Igual 100 sería mejor?*)"
      ],
      "metadata": {
        "id": "uIEk5CTgJEbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_2 = ZFeatureMap(X_train.shape[1], reps=2)\n",
        "ansatz_su2_2 = EfficientSU2(num_qubits=X_train.shape[1],\n",
        "                            reps=1)\n",
        "optimizer_cobyla_2 = COBYLA(maxiter=100, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc_2 = VQC(feature_map=z_feature_map_2, ansatz=ansatz_su2_2, optimizer=optimizer_cobyla_2)\n",
        "\n",
        "start = time.time()\n",
        "vqc_2.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.3f} minutos\")\n",
        "\n",
        "train_score = vqc_2.score(X_train, y_train)\n",
        "test_score = vqc_2.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL7TYnXsJ_gl",
        "outputId": "b2c4164b-1a31-42b1-b5b0-961fad5dbac5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 49.059 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.5985915492957746\n",
            "Precisión del VQC en el conjunto de prueba: 0.6944444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo algo más robusto e igual más baloanceado**\n",
        "\n",
        "*Siguen siendo modelos simples pero que creo que pueden ya modelar relaciones batante relevantes. Aquí voy a probar con menos iteraciones que empiezo a percibir tiempo de ejecución muy largos*\n",
        "\n",
        "- **MODELO-3**\n",
        "\n",
        "  *   **ZZFeatureMap**: 2 repeticiones\n",
        "  *   **RealAmplitudes**: 2 repetición\n",
        "  *   **COBYLA**: 100 interacciones"
      ],
      "metadata": {
        "id": "cqpaVFaLKSQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zz_feature_map_3 = ZZFeatureMap(feature_dimension=X_train.shape[1], reps=2)\n",
        "ansatz_amplitudes_3 = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='linear',\n",
        "                        reps=2)\n",
        "optimizer_cobyla_3 = COBYLA(maxiter=100, tol=1e-3)\n",
        "\n",
        "vqc_3 = VQC(feature_map=zz_feature_map_3, ansatz=ansatz_amplitudes_3, optimizer=optimizer_cobyla_3)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "vqc_3.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time} segundos\")\n",
        "\n",
        "train_score = vqc_3.score(X_train, y_train)\n",
        "test_score = vqc_3.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXkRg7G0Mwwi",
        "outputId": "0d3ad157-0005-4918-8b62-aef58f369c07"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 4254.173606157303 segundos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.4788732394366197\n",
            "Precisión del VQC en el conjunto de prueba: 0.6111111111111112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "elapsed_time_minutes = elapsed_time / 60  # Convertir segundos a minutos\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.2f} minutos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awPRofxdLJQo",
        "outputId": "b14db3e7-4c92-4d58-e21f-234af759d4db"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 70.90 minutos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Modelo algo más complejo**\n",
        "\n",
        "*Esta combinación es más poderosa para capturar patrones complejos en los datos, pero podría ser más lenta de optimizar*\n",
        "\n",
        "  -  **MODELO-4**\n",
        "     *  **ZZFeatureMap**: 2 repeticiones\n",
        "     *  **TwoLocal**: 2 repetición\n",
        "     *  **Adam**: 100 interacciones\n",
        "\n"
      ],
      "metadata": {
        "id": "vhMYHyDLO-_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zz_feature_map_4 = ZZFeatureMap(feature_dimension=X_train.shape[1], reps=2)\n",
        "ansatz_twolocal = TwoLocal(num_qubits=X_train.shape[1],\n",
        "                           rotation_blocks='ry',\n",
        "                           entanglement_blocks='cz',\n",
        "                           reps=2)\n",
        "optimizer_adam = ADAM(maxiter=100, lr=0.01)\n",
        "\n",
        "\n",
        "vqc_4 = VQC(feature_map=zz_feature_map_3, ansatz=ansatz_amplitudes, optimizer=optimizer_cobyla_3)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "vqc_4.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.2f} minutos\")\n",
        "\n",
        "train_score = vqc_4.score(X_train, y_train)\n",
        "test_score = vqc_4.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNYqzLBpPVLB",
        "outputId": "318daebb-1549-4704-b647-45239182a77e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 70.75 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.5070422535211268\n",
            "Precisión del VQC en el conjunto de prueba: 0.6111111111111112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora despues de ver estos resultamos podemos probar combinaciones diferentes haber si conseguimos mejorar los resultados"
      ],
      "metadata": {
        "id": "0EBKpt2zdz4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Vamos a probar el modelo 2 pero con otro ansatz a ver que ocurre ya que es el modelo que de momento ha mostrado el mejor resultado*\n",
        "\n",
        "  *  **MODELO-5**\n",
        "      *  **ZZFeatureMap**: 2 repeticiones\n",
        "      *  **TwoLocal**: 3 repetición\n",
        "      *  **COBYLA**: 100 interacciones\n"
      ],
      "metadata": {
        "id": "VYKaDS3Yd_rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_5 = ZFeatureMap(X_train.shape[1], reps=2)\n",
        "ansatz_twolocal_5 = TwoLocal(num_qubits=X_train.shape[1],\n",
        "                           rotation_blocks='ry',\n",
        "                           entanglement_blocks='cz',\n",
        "                           reps=3)\n",
        "optimizer_cobyla_5 = COBYLA(maxiter=100, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc_5 = VQC(feature_map=z_feature_map_5, ansatz=ansatz_twolocal_5, optimizer=optimizer_cobyla_5)\n",
        "\n",
        "start = time.time()\n",
        "vqc_5.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.3f} minutos\")\n",
        "\n",
        "train_score = vqc_5.score(X_train, y_train)\n",
        "test_score = vqc_5.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZxMU9oIeg9s",
        "outputId": "793658da-df9a-489c-d0d9-9eaf6ff4aea2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 61.238 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.5845070422535211\n",
            "Precisión del VQC en el conjunto de prueba: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*Vamos a probar con un ansatz  distinto*\n",
        "\n",
        "  *  **MODELO-6**\n",
        "      *  **ZZFeatureMap**: 2 repeticiones\n",
        "      *  **RealEstimation**: 3 repetición\n",
        "      *  **COBYLA**: 100 interacciones\n",
        "\n"
      ],
      "metadata": {
        "id": "JNV88-I6uOOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_6 = ZFeatureMap(X_train.shape[1], reps=2)\n",
        "ansatz_amplitudes_6 = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='linear',\n",
        "                        reps=3)\n",
        "optimizer_cobyla_6 = COBYLA(maxiter=100, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc_6 = VQC(feature_map=z_feature_map_6, ansatz=ansatz_amplitudes_6, optimizer=optimizer_cobyla_6)\n",
        "\n",
        "start = time.time()\n",
        "vqc_6.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.3f} minutos\")\n",
        "\n",
        "train_score = vqc_6.score(X_train, y_train)\n",
        "test_score = vqc_6.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17wr5VAkv31H",
        "outputId": "b7ca1ab2-bd87-45eb-eff8-b1950c523aa0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 55.003 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.6408450704225352\n",
            "Precisión del VQC en el conjunto de prueba: 0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*Tiene buena pinta, vamos a subir las repeticiones del feature map a ver si eso ayuda algo y tambien las interacciones máximas del cobyla*\n",
        "\n",
        "  *  **MODELO-8**\n",
        "     *   **ZFeatureMap**: 3 repeticiones\n",
        "     *   **RealEstimation**: 3 repetición\n",
        "     *   **COBYLA**: 150 interacciones\n",
        "\n"
      ],
      "metadata": {
        "id": "a46J-RX39D67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_7 = ZFeatureMap(X_train.shape[1], reps=3)\n",
        "ansatz_amplitudes_7 = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='linear',\n",
        "                        reps=3)\n",
        "optimizer_cobyla_7 = COBYLA(maxiter=150, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc_7 = VQC(feature_map=z_feature_map_7, ansatz=ansatz_amplitudes_7, optimizer=optimizer_cobyla_7)\n",
        "\n",
        "start = time.time()\n",
        "vqc_7.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.3f} minutos\")\n",
        "\n",
        "train_score = vqc_7.score(X_train, y_train)\n",
        "test_score = vqc_7.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RFek5JH9Cuj",
        "outputId": "f2123dbc-87e4-4f39-d46d-9b778d56ba41"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 76.194 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.6056338028169014\n",
            "Precisión del VQC en el conjunto de prueba: 0.7222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Voy a intentar superar ese 77% con un modelo algo más exigente en cuanto a recursos computacionales y algo más lento *\n",
        "\n",
        "  *  **MODELO-8**\n",
        "     *   **ZFeatureMap**: 3 repeticiones\n",
        "     *   **RealEstimation**: 3 repetición **Full Entanglement**\n",
        "     *   **COBYLA**: 200 interacciones\n"
      ],
      "metadata": {
        "id": "nReUQ6tL_9MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_8 = ZFeatureMap(X_train.shape[1], reps=3)\n",
        "ansatz_amplitudes_8 = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='full',\n",
        "                        reps=3)\n",
        "optimizer_cobyla_8 = COBYLA(maxiter=200, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc_8 = VQC(feature_map=z_feature_map_8, ansatz=ansatz_amplitudes_8, optimizer=optimizer_cobyla_8)\n",
        "\n",
        "start = time.time()\n",
        "vqc_8.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.3f} minutos\")\n",
        "\n",
        "train_score = vqc_8.score(X_train, y_train)\n",
        "test_score = vqc_8.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc9T5y1t_tNB",
        "outputId": "57a6e28f-795d-40aa-9133-e8822917b7e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 118.787 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.5915492957746479\n",
            "Precisión del VQC en el conjunto de prueba: 0.6944444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Voy a intentar con el modelo 6 y solo más interaccione a ver si así notamos mejoría*\n",
        "\n",
        "  *  **MODELO-9**\n",
        "     *   **ZFeatureMap**: 2 repeticiones\n",
        "     *   **RealEstimation**: 4 repetición Entanglement\n",
        "     *   **COBYLA**: 100 interacciones\n"
      ],
      "metadata": {
        "id": "mZjdUY9SNUFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_9 = ZFeatureMap(X_train.shape[1], reps=2)\n",
        "ansatz_amplitudes_9 = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='linear',\n",
        "                        reps=4)\n",
        "optimizer_cobyla_9= COBYLA(maxiter=100, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc_9 = VQC(feature_map=z_feature_map_9, ansatz=ansatz_amplitudes_9, optimizer=optimizer_cobyla_9)\n",
        "\n",
        "start = time.time()\n",
        "vqc_9.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.3f} minutos\")\n",
        "\n",
        "train_score = vqc_9.score(X_train, y_train)\n",
        "test_score = vqc_9.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L97LH_0ONJKy",
        "outputId": "64418924-6118-477a-863e-e52a981b403e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 54.967 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.6338028169014085\n",
            "Precisión del VQC en el conjunto de prueba: 0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*¿Igual el mismo y más iteraciones?*\n",
        "\n",
        "  *  **MODELO-10**\n",
        "     *   **ZFeatureMap**: 2 repeticiones\n",
        "     *   **RealEstimation**: 4 repetición Entanglement\n",
        "     *   **COBYLA**: 500 interacciones"
      ],
      "metadata": {
        "id": "nIc6wCam-P3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z_feature_map_10 = ZFeatureMap(X_train.shape[1], reps=2)\n",
        "ansatz_amplitudes_10 = RealAmplitudes(num_qubits=X_train.shape[1],\n",
        "                        entanglement='linear',\n",
        "                        reps=4)\n",
        "optimizer_cobyla_10 = COBYLA(maxiter=500, tol=1e-3)\n",
        "\n",
        "\n",
        "vqc_10 = VQC(feature_map=z_feature_map_10, ansatz=ansatz_amplitudes_10, optimizer=optimizer_cobyla_10)\n",
        "\n",
        "start = time.time()\n",
        "vqc_10.fit(X_train, y_train)\n",
        "elapsed_time = time.time() - start\n",
        "elapsed_time_minutes = elapsed_time / 60\n",
        "print(f\"Tiempo de entrenamiento: {elapsed_time_minutes:.3f} minutos\")\n",
        "\n",
        "train_score = vqc_10.score(X_train, y_train)\n",
        "test_score = vqc_10.score(X_test, y_test)\n",
        "print(f\"Precisión del VQC en el conjunto de entrenamiento: {train_score}\")\n",
        "print(f\"Precisión del VQC en el conjunto de prueba: {test_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hb-vyXr-Oz-",
        "outputId": "aed7a40e-5479-4db1-8d45-cd5e7f9f6f1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento: 261.183 minutos\n",
            "Precisión del VQC en el conjunto de entrenamiento: 0.6619718309859155\n",
            "Precisión del VQC en el conjunto de prueba: 0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*¿Será este el límite que se puede alcanzar de precisión?"
      ],
      "metadata": {
        "id": "1T1Hhg1GvAWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusiones**\n",
        "\n",
        "Tras todas estas pruebas hemos podido observar que los mejores resultados los han proporcionado los modelos 6 y 9, ambos alcanzando un 77.78% de precisión máxima, utilizando ZFeatureMap, RealAmplitude (con entrelazamiento lineal) y el optimizador COBYLA. El Modelo 10 es un claro ejemplo de que puede que 77,78% sea nuestro límite actual o al menos que ese nivel de precisión no se puede superar solo con un mayor número de iteracciones. Se ha percibido tambien que usar \"Full Entanglement\" no supone una mayor precisión en este dispositivo de pruebas. También se observa que ZZFeatureMap, no es el Feature Map que más potencial nos puede ofrecer en datasets como el nuestro, al igual que el optimizador Adam.\n",
        "¿Habré cometido algun error? ¿Habre ajustado de mala manera algún parámetro? Puede ser, soy consciente de que igual no he probado todas las opciones posibles y que podría escaparseme agún detalle importante. Puede que la parametrización o el preprocesamiento de los datos no sea el que más potencial puede sacar de este dataset. Igual tambien he pasado por alto algún optimizador con potencial, igualmente creo que se ha alcanzado un buen reesultado, que aunque no iguala a la precisión de los métodos clásicos es un buen resultado."
      ],
      "metadata": {
        "id": "IAVvckQtbjnj"
      }
    }
  ]
}